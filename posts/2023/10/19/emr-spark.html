<!doctype html><html lang="en" ><head> <script async src="https://www.googletagmanager.com/gtag/js?id=G-LXECFRDHS1"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-LXECFRDHS1'); </script><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="Running Recommendation Engine Spark Job on EMR | by Roman Tsypuk" /><meta name="author" content="Roman Tsypuk" /><meta property="og:locale" content="en" /><meta name="description" content="Amazon Elastic MapReduce (EMR) is a managed big data service that simplifies the process of processing and analyzing large datasets using popular frameworks like Apache Spark, Hadoop, and others. In this post, we’ll focus on using EMR with Apache Spark to read data from Amazon S3, a scalable object storage service offered by AWS." /><meta property="og:description" content="Amazon Elastic MapReduce (EMR) is a managed big data service that simplifies the process of processing and analyzing large datasets using popular frameworks like Apache Spark, Hadoop, and others. In this post, we’ll focus on using EMR with Apache Spark to read data from Amazon S3, a scalable object storage service offered by AWS." /><meta property="twitter:description" content="Amazon Elastic MapReduce (EMR) is a managed big data service that simplifies the process of processing and analyzing large datasets using popular frameworks like Apache Spark, Hadoop, and others. In this post, we’ll focus on using EMR with Apache Spark to read data from Amazon S3, a scalable object storage service offered by AWS." /><link rel="canonical" href="https://tsypuk.github.io/posts/2023/10/19/emr-spark.html" /><meta property="og:url" content="https://tsypuk.github.io/posts/2023/10/19/emr-spark.html" /><meta property="og:site_name" content="Engineer’s Notes | Roman Tsypuk" /><meta property="og:image" content="https://tsypuk.github.io/images/banners/1200/pexels-mike-bird-190574.jpeg" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-10-19T17:00:00+03:00" /><meta name="publish_date" property="og:publish_date" content="2023-10-19T17:00:00+03:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://tsypuk.github.io/images/banners/1200/pexels-mike-bird-190574.jpeg" /><meta property="twitter:title" content="Running Recommendation Engine Spark Job on EMR | by Roman Tsypuk" /><meta name="twitter:site" content="@roman_tsypuk" /><meta name="twitter:creator" content="@roman_tsypuk" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Roman Tsypuk"},"dateModified":"2024-02-25T18:38:06+02:00","datePublished":"2023-10-19T17:00:00+03:00","description":"Amazon Elastic MapReduce (EMR) is a managed big data service that simplifies the process of processing and analyzing large datasets using popular frameworks like Apache Spark, Hadoop, and others. In this post, we’ll focus on using EMR with Apache Spark to read data from Amazon S3, a scalable object storage service offered by AWS.","headline":"Running Recommendation Engine Spark Job on EMR","image":"https://tsypuk.github.io/images/banners/1200/pexels-mike-bird-190574.jpeg","mainEntityOfPage":{"@type":"WebPage","@id":"https://tsypuk.github.io/posts/2023/10/19/emr-spark.html"},"url":"https://tsypuk.github.io/posts/2023/10/19/emr-spark.html"}</script><title>Running Recommendation Engine Spark Job on EMR | Engineer's Notes</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Engineer's Notes"><meta name="application-name" content="Engineer's Notes"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js?baseurl=&register=" ></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-LXECFRDHS1"></script> <script> document.addEventListener('DOMContentLoaded', () => { window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-LXECFRDHS1'); }); </script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/images/avatar/rtsypuk.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">Engineer's Notes</a><p class="site-subtitle fst-italic mb-0">Cloud, Infrastructure, Architecture, Networking</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories.html" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags.html" class="nav-link"> <i class="fa-fw fas fa-tag"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archived_posts.html" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/roman_tsypuk.html" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/tsypuk" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="https://twitter.com/roman_tsypuk" aria-label="twitter" target="_blank" rel="noopener noreferrer" > <i class="fab fa-twitter"></i> </a> <a href="https://www.linkedin.com/in/roman-tsypuk" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="javascript:location.href = 'mailto:' + ['tsypuk_conf','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>Running Recommendation Engine Spark Job on EMR</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link" aria-label="Search"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>Running Recommendation Engine Spark Job on EMR</h1><div class="post-meta text-muted"> <span> Posted <time data-ts="1697724000" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Oct 19, 2023 </time> </span> <span> Updated <time data-ts="1708879086" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Feb 25, 2024 </time> </span><div class="mt-3 mb-3"> <a href="/images/banners/1200/pexels-mike-bird-190574.jpeg" class="popup img-link preview-img shimmer"><img src="/images/banners/1200/pexels-mike-bird-190574.jpeg" alt="Preview Image" width="1200" height="630" loading="lazy"></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://www.linkedin.com/in/roman-tsypuk">Roman Tsypuk</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1576 words" > <em>8 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">Running Recommendation Engine Spark Job on EMR</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">Running Recommendation Engine Spark Job on EMR</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><h2 id="abstract"><span class="me-2">Abstract</span><a href="#abstract" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>Amazon Elastic MapReduce (EMR) is a managed big data service that simplifies the process of processing and analyzing large datasets using popular frameworks like Apache Spark, Hadoop, and others. In this post, we’ll focus on using EMR with Apache Spark to read data from Amazon S3, a scalable object storage service offered by AWS.</p><h2 id="target-infrastructure"><span class="me-2">Target Infrastructure</span><a href="#target-infrastructure" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p><a href="/images/posts/emr/infra.png" class="popup img-link shimmer"><img src="/images/posts/emr/infra.png" alt="infra.png" loading="lazy"></a></p><h2 id="emr-setup"><span class="me-2">EMR Setup</span><a href="#emr-setup" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><h3 id="frameworks-and-versions-configuration"><span class="me-2">Frameworks and versions configuration</span><a href="#frameworks-and-versions-configuration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Setting up an EMR cluster from the AWS Console is a easy thanks to the intuitive wizard steps. The latest available EMR version, <code class="language-plaintext highlighter-rouge">emr-6.13.0</code>, ensures you have access to the most up-to-date features and improvements.</p><p>During the configuration process, you have the flexibility to choose from a variety of frameworks. These frameworks are automatically provisioned and ready to use on your EMR cluster. Should you require a specific version, you can easily adjust it to meet your needs.</p><p>One of the standout features of EMR is the provision of preconfigured installations. AWS offers a selection of installations with different engines and compatible versions that have undergone rigorous testing and alignment. This is a game-changer in the Big Data landscape, as it eliminates the challenges and <strong>BIG</strong> pain in Big Data World of assembling a distribution with all frameworks precisely aligned to dedicated versions and simplifies the upgrade process. With EMR, everything is prepped and ready for seamless use.</p><p><a href="/images/posts/emr/img.png" class="popup img-link shimmer"><img src="/images/posts/emr/img.png" alt="img.png" loading="lazy"></a></p><h3 id="primary-node-capacity"><span class="me-2">Primary node capacity</span><a href="#primary-node-capacity" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>The primary node serves as the central management hub for the cluster. It oversees critical components of distributed applications, including the YARN ResourceManager service for resource management. Additionally, the primary node is responsible for running the HDFS NameNode service, keeping track of job statuses, and monitoring the overall health of the instance groups.</p><p><a href="/images/posts/emr/img_1.png" class="popup img-link shimmer"><img src="/images/posts/emr/img_1.png" alt="img_1.png" loading="lazy"></a></p><h3 id="core-node-capacity"><span class="me-2">Core node capacity</span><a href="#core-node-capacity" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Under the primary node’s management, core nodes play a pivotal role in data coordination within the Hadoop Distributed File System (HDFS). They execute the Data Node daemon, which handles data storage tasks. Core nodes are also responsible for running the Task Tracker daemon, performing parallel computations required by installed applications. For instance, a core node hosts YARN NodeManager daemons, executes Hadoop MapReduce tasks, and handles Spark executors.</p><h3 id="task-node-capacity"><span class="me-2">Task node capacity</span><a href="#task-node-capacity" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Task nodes are your go-to choice when you need additional processing power. They excel at executing tasks like Hadoop MapReduce tasks and Spark executors. Unlike core nodes, task nodes do not run the Data Node daemon, nor do they store data in HDFS. To incorporate task nodes into your cluster, you can either add Amazon EC2 instances to an existing uniform instance group or adjust target capacities for a task instance fleet. This flexibility allows you to fine-tune your cluster’s computational capabilities to meet specific workload requirements.</p><p><a href="/images/posts/emr/img_2.png" class="popup img-link shimmer"><img src="/images/posts/emr/img_2.png" alt="img_2.png" loading="lazy"></a></p><h3 id="cluster-size"><span class="me-2">Cluster size</span><a href="#cluster-size" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Based on workload time you can configure and tune cluster capacity with autoscaling options.</p><p><a href="/images/posts/emr/img_3.png" class="popup img-link shimmer"><img src="/images/posts/emr/img_3.png" alt="img_3.png" loading="lazy"></a></p><h3 id="acces-to-s3-with-data"><span class="me-2">Acces to S3 with Data</span><a href="#acces-to-s3-with-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/images/posts/emr/img_5.png" class="popup img-link shimmer"><img src="/images/posts/emr/img_5.png" alt="img_5.png" loading="lazy"></a></p><h3 id="enable-access-to-nodes-from-your-machine"><span class="me-2">Enable access to Nodes from your machine</span><a href="#enable-access-to-nodes-from-your-machine" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>By default, when EMR is created there is no access to nodes for end-user. We need to edit <code class="language-plaintext highlighter-rouge">Security Group</code> of the Primary Node and add appropriate rule to access EC2 instance.</p><p>After configuring <code class="language-plaintext highlighter-rouge">SG</code> we can ssh into Primary node of EMR:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
</pre><td class="rouge-code"><pre> ssh <span class="nt">-i</span> ~/ssh.pem hadoop@ec2-xx-xxx-xxx-xx.eu-west-1.compute.amazonaws.com
   ,     <span class="c">#_</span>
   ~<span class="se">\_</span>  <span class="c">####_        Amazon Linux 2</span>
  ~~  <span class="se">\_</span><span class="c">#####\</span>
  ~~     <span class="se">\#</span><span class="c">##|       AL2 End of Life is 2025-06-30.</span>
  ~~       <span class="se">\#</span>/ ___
   ~~       V~<span class="s1">' '</span>-&gt;
    ~~~         /    A newer version of Amazon Linux is available!
      ~~._.   _/
         _/ _/       Amazon Linux 2023, GA and supported <span class="k">until </span>2028-03-15.
       _/m/<span class="s1">'           https://aws.amazon.com/linux/amazon-linux-2023/

5 package(s) needed for security, out of 11 available
Run "sudo yum update" to apply all updates.

EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR
E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R
EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R
  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R
  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R
  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R
  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR
  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R
  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R
  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R
EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R
E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R
EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR

[hadoop@ip-xxx-xx-xx-xx ~]$
</span></pre></table></code></div></div><h3 id="access-to-yarn-spark-history"><span class="me-2">Access to YARN, Spark History:</span><a href="#access-to-yarn-spark-history" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>You can use ssh tunnel to expose EMR ports with YARN, Spark to you local machine and access them. But in the latest EMR UI version AWS Console provides link to navigate directly to provisioned proxy instances.</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>ssh <span class="nt">-i</span> ~/key.cer <span class="nt">-L</span> 3000:ec2-xx-xxx-xxx-xx.eu-west-1.compute.amazonaws.com:8088 hadoop@ec2-xx-xxx-xxx-xx.eu-west-1.compute.amazonaws.com
</pre></table></code></div></div><p><a href="/images/posts/emr/img_6.png" class="popup img-link shimmer"><img src="/images/posts/emr/img_6.png" alt="img_6.png" loading="lazy"></a></p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>ssh <span class="nt">-i</span> ~/key.cer  <span class="nt">-L</span> 4040:SPARK_UI_NODE_URL:4040 hadoop@ec2-xx-xx-xx-xx.eu-west-1.compute.amazonaws.com
ssh <span class="nt">-i</span> ~/key.cer <span class="nt">-N</span> <span class="nt">-L</span> 20888:ip-xx-xx-xx-xx.your-region.compute.internal:20888 hadoop@ec2-xxx.compute.amazonaws.com
ssh <span class="nt">-i</span> ~/key.cer <span class="nt">-L</span> 3000:ec2-xx-xx-xx-xx.eu-west-1.compute.amazonaws.com:8088 hadoop@ec2-xx-xx-xx-xx.eu-west-1.compute.amazonaws.com
ssh <span class="nt">-i</span> ~/key.cer <span class="nt">-L</span> 4040:ec2-xx-xx-xx-xx.eu-west-1.compute.amazonaws.com:4040 hadoop@ec2-xxx-xx-xx-xx.eu-west-1.compute.amazonaws.com
</pre></table></code></div></div><h2 id="running-sample-spark-job"><span class="me-2">Running Sample Spark Job</span><a href="#running-sample-spark-job" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>To test EMR Spark functionality we will start with predefided Spark sample app, let’s dive into its details.</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">cp</span> /usr/lib/spark/examples/src/main/python/ml/als_example.py ./
</pre></table></code></div></div><h3 id="spark-load-data-from-hdfs-splited-based-on--delimiter-to-userid-movieid-rating-timestamp"><span class="me-2">Spark Load Data from <code class="language-plaintext highlighter-rouge">HDFS</code>, splited based on <code class="language-plaintext highlighter-rouge">::</code> delimiter to <code class="language-plaintext highlighter-rouge">userID</code>, <code class="language-plaintext highlighter-rouge">movieID</code>, <code class="language-plaintext highlighter-rouge">rating</code>, <code class="language-plaintext highlighter-rouge">timestamp</code>:</span><a href="#spark-load-data-from-hdfs-splited-based-on--delimiter-to-userid-movieid-rating-timestamp" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">lines</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="sh">"</span><span class="s">data/mllib/als/sample_movielens_ratings.txt</span><span class="sh">"</span><span class="p">).</span><span class="n">rdd</span>
    <span class="n">parts</span> <span class="o">=</span> <span class="n">lines</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">value</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">::</span><span class="sh">"</span><span class="p">))</span>
    <span class="n">ratingsRDD</span> <span class="o">=</span> <span class="n">parts</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="nc">Row</span><span class="p">(</span><span class="n">userId</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">movieId</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                         <span class="n">rating</span><span class="o">=</span><span class="nf">float</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="n">timestamp</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">])))</span>
    <span class="n">ratings</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">ratingsRDD</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="spark-train-model-for-recommendations-using-als-on-training-data"><span class="me-2">Spark Train Model for recommendations using ALS on training Data:</span><a href="#spark-train-model-for-recommendations-using-als-on-training-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>    <span class="n">als</span> <span class="o">=</span> <span class="nc">ALS</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">userCol</span><span class="o">=</span><span class="sh">"</span><span class="s">userId</span><span class="sh">"</span><span class="p">,</span> <span class="n">itemCol</span><span class="o">=</span><span class="sh">"</span><span class="s">movieId</span><span class="sh">"</span><span class="p">,</span> <span class="n">ratingCol</span><span class="o">=</span><span class="sh">"</span><span class="s">rating</span><span class="sh">"</span><span class="p">,</span>
              <span class="n">coldStartStrategy</span><span class="o">=</span><span class="sh">"</span><span class="s">drop</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">als</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="predictions-model-evaluation"><span class="me-2">Predictions, Model Evaluation:</span><a href="#predictions-model-evaluation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><ul><li>generate top 10 movie recommendations for each user<li>generate top 10 user recommendations for each movie</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
    <span class="n">evaluator</span> <span class="o">=</span> <span class="nc">RegressionEvaluator</span><span class="p">(</span><span class="n">metricName</span><span class="o">=</span><span class="sh">"</span><span class="s">rmse</span><span class="sh">"</span><span class="p">,</span> <span class="n">labelCol</span><span class="o">=</span><span class="sh">"</span><span class="s">rating</span><span class="sh">"</span><span class="p">,</span>
                                    <span class="n">predictionCol</span><span class="o">=</span><span class="sh">"</span><span class="s">prediction</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">evaluator</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Root-mean-square error = </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">rmse</span><span class="p">))</span>

    <span class="n">userRecs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">recommendForAllUsers</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">movieRecs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">recommendForAllItems</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>generate top 10 movie recommendations for a specified set of users<li>generate top 10 user recommendations for a specified set of movies</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>
    <span class="n">users</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="n">als</span><span class="p">.</span><span class="nf">getUserCol</span><span class="p">()).</span><span class="nf">distinct</span><span class="p">().</span><span class="nf">limit</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">userSubsetRecs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">recommendForUserSubset</span><span class="p">(</span><span class="n">users</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="n">movies</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="n">als</span><span class="p">.</span><span class="nf">getItemCol</span><span class="p">()).</span><span class="nf">distinct</span><span class="p">().</span><span class="nf">limit</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">movieSubSetRecs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">recommendForItemSubset</span><span class="p">(</span><span class="n">movies</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="load-data-to-hdfs"><span class="me-2">Load data to HDFS</span><a href="#load-data-to-hdfs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>DataSet is available at <a href="https://github.com/tsypuk/samples/tree/main/emr">https://github.com/tsypuk/samples/tree/main/emr</a> to copy it to <code class="language-plaintext highlighter-rouge">HDFS</code> we are using <code class="language-plaintext highlighter-rouge">hadoop cli</code></p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>hadoop fs <span class="nt">-mkdir</span> <span class="nt">-p</span> /user/hadoop/data/mllib/als
hadoop fs <span class="nt">-copyFromLocal</span> /usr/lib/spark/data/mllib/als/sample_movielens_ratings.txt /user/hadoop/data/mllib/als/sample_movielens_ratings.txt
</pre></table></code></div></div><h3 id="optional-stage"><span class="me-2">Optional Stage</span><a href="#optional-stage" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Modify spark Job to have less output in logs</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>spark.sparkContext.setLogLeve<span class="o">(</span><span class="s2">"ERROR"</span><span class="o">)</span>
</pre></table></code></div></div><h3 id="submitting-spark-job"><span class="me-2">Submitting Spark Job</span><a href="#submitting-spark-job" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="o">[</span>hadoop@ip-xxx-xx-xx-xx ~]<span class="nv">$ </span>spark-submit als_example.py
23/10/18 14:03:34 INFO SparkContext: Running Spark version 3.4.1-amzn-0
23/10/18 14:03:34 INFO ResourceUtils: <span class="o">==============================================================</span>
23/10/18 14:03:34 INFO ResourceUtils: No custom resources configured <span class="k">for </span>spark.driver.
23/10/18 14:03:34 INFO ResourceUtils: <span class="o">==============================================================</span>
23/10/18 14:03:34 INFO SparkContext: Submitted application: ALSExample
23/10/18 14:03:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map<span class="o">(</span>cores -&gt; name: cores, amount: 4, script: , vendor: , memory -&gt; name: memory, amount: 9486, script: , vendor: , offHeap -&gt; name: offHeap, amount: 0, script: , vendor: <span class="o">)</span>, task resources: Map<span class="o">(</span>cpus -&gt; name: cpus, amount: 1.0<span class="o">)</span>
</pre></table></code></div></div><h3 id="results-and-status-are-available-on-ui"><span class="me-2">Results and Status are available on UI</span><a href="#results-and-status-are-available-on-ui" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/images/posts/emr/img_7.png" class="popup img-link shimmer"><img src="/images/posts/emr/img_7.png" alt="img_7.png" loading="lazy"></a></p><h3 id="output-of-results-in-console"><span class="me-2">Output of results in console:</span><a href="#output-of-results-in-console" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Here are recommendations for each user for current DataSet:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre>+------+--------------------+
|userId|     recommendations|
+------+--------------------+
|     4|[<span class="o">{</span>41, 4.165862<span class="o">}</span>, ...|
|    14|[<span class="o">{</span>76, 4.606556<span class="o">}</span>, ...|
|    24|[<span class="o">{</span>69, 5.097545<span class="o">}</span>, ...|
|     5|[<span class="o">{</span>55, 4.787237<span class="o">}</span>, ...|
|    15|[<span class="o">{</span>46, 4.87731<span class="o">}</span>, <span class="o">{</span>...|
|    25|[<span class="o">{</span>38, 4.6747584<span class="o">}</span>,...|
|     6|[<span class="o">{</span>62, 4.7941403<span class="o">}</span>,...|
|    16|[<span class="o">{</span>85, 5.0937176<span class="o">}</span>,...|
|    26|[<span class="o">{</span>74, 5.545739<span class="o">}</span>, ...|
|    27|[<span class="o">{</span>18, 4.022548<span class="o">}</span>, ...|
|    17|[<span class="o">{</span>27, 5.4436226<span class="o">}</span>,...|
|     7|[<span class="o">{</span>25, 4.7733192<span class="o">}</span>,...|
|    20|[<span class="o">{</span>22, 4.6535172<span class="o">}</span>,...|
|     0|[<span class="o">{</span>92, 3.967172<span class="o">}</span>, ...|
|    10|[<span class="o">{</span>2, 3.6862848<span class="o">}</span>, ...|
|     1|[<span class="o">{</span>68, 3.9590843<span class="o">}</span>,...|
|    11|[<span class="o">{</span>27, 4.9718685<span class="o">}</span>,...|
|    21|[<span class="o">{</span>53, 4.8786216<span class="o">}</span>,...|
|    12|[<span class="o">{</span>46, 6.7249556<span class="o">}</span>,...|
|     2|[<span class="o">{</span>83, 5.306094<span class="o">}</span>, ...|
+------+--------------------+
only showing top 20 rows
</pre></table></code></div></div><h2 id="switching-emr-spark-to-query-aws-s3"><span class="me-2">Switching EMR Spark to query AWS S3</span><a href="#switching-emr-spark-to-query-aws-s3" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>It was sampled Spark job that works with <code class="language-plaintext highlighter-rouge">HDFS</code>, but for EMR <code class="language-plaintext highlighter-rouge">AWS S3</code> is available</p><p>DataSet located <code class="language-plaintext highlighter-rouge">S3</code> bucket (with prefixed virtual path based on timeline) we will use from the previous post <a href="/posts/2023/10/18/kineses-firehose.html">Connecting Kinesis Firehose DataStream with aws-kinesis-agent to ingest Log Data into AWS S3</a></p><p>To make EMR Spark work with S3 we need to modify the Job file:</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">lines</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="sh">"</span><span class="s">s3://kl-bucket-2023/year=2023/month=10/day=18/hour=13/*</span><span class="sh">"</span><span class="p">).</span><span class="n">rdd</span>
<span class="n">parts</span> <span class="o">=</span> <span class="n">lines</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">value</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">))</span>
<span class="c1">#Filter out postage, shipping, bank charges, discounts, commissions
</span><span class="n">productsOnly</span> <span class="o">=</span> <span class="n">parts</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">].</span><span class="nf">isdigit</span><span class="p">())</span>
<span class="c1">#Filter out empty customer ID's
</span><span class="n">cleanData</span> <span class="o">=</span> <span class="n">productsOnly</span><span class="p">.</span><span class="nf">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">].</span><span class="nf">isdigit</span><span class="p">())</span>
<span class="n">ratingsRDD</span> <span class="o">=</span> <span class="n">cleanData</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="nc">Row</span><span class="p">(</span><span class="n">customerId</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">]),</span> \
<span class="n">itemId</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]),</span> <span class="n">rating</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>
</pre></table></code></div></div><h3 id="troubleshooting-the-issue"><span class="me-2">Troubleshooting the issue</span><a href="#troubleshooting-the-issue" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>I case you receive you receiving following error when running Job:</p><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Caused by: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied (Service: Amazon S3; Status Code: 403; Error Code: AccessDenied;
</pre></table></code></div></div><p>Try to check if EMR has access to S3 by running the following cli command:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>hdfs dfs <span class="nt">-ls</span> s3://kl-bucket-2023/year<span class="o">=</span>2023/month<span class="o">=</span>10/day<span class="o">=</span>18/hour<span class="o">=</span>13/<span class="k">*</span>
<span class="nb">ls</span>: com.amazon.ws.emr.hadoop.fs.shaded.com.amazonaws.services.s3.model.AmazonS3Exception: Access Denied
</pre></table></code></div></div><p>If error - check Service Role and EC2 instance profile - they should have access to your <code class="language-plaintext highlighter-rouge">s3 bucket</code>. Once permissions are setup, you should see the proper bucket listing:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="o">[</span>hadoop@ip-xx-xx-xx-xx ~]<span class="nv">$ </span>hdfs dfs <span class="nt">-ls</span> s3://kl-bucket-2023hdfs dfs <span class="nt">-ls</span> s3://kl-bucket-2023/year<span class="o">=</span>2023/month<span class="o">=</span>10/day<span class="o">=</span>18/hour<span class="o">=</span>13/<span class="k">*</span>
<span class="nt">-rw-rw-rw-</span>   1 hadoop hadoop     423974 2023-10-18 13:02 s3://kl-bucket-2023/year<span class="o">=</span>2023/month<span class="o">=</span>10/day<span class="o">=</span>18/hour<span class="o">=</span>13/terraform-kinesis-firehose-logs-s3-stream-1-2023-10-18-13-01-08-e7f44bf7-b2e0-43b7-ad1c-11d74c7383fa
<span class="nt">-rw-rw-rw-</span>   1 hadoop hadoop     837497 2023-10-18 13:13 s3://kl-bucket-2023/year<span class="o">=</span>2023/month<span class="o">=</span>10/day<span class="o">=</span>18/hour<span class="o">=</span>13/terraform-kinesis-firehose-logs-s3-stream-1-2023-10-18-13-12-31-efad7e9e-89a1-4478-9a09-b954dd83c48d
<span class="nt">-rw-rw-rw-</span>   1 hadoop hadoop    1257779 2023-10-18 13:14 s3://kl-bucket-2023/year<span class="o">=</span>2023/month<span class="o">=</span>10/day<span class="o">=</span>18/hour<span class="o">=</span>13/terraform-kinesis-firehose-logs-s3-stream-1-2023-10-18-13-13-43-35e7b0b8-90a4-449a-b373-82f14e28032f
</pre></table></code></div></div><h3 id="running-spark-job-on-top-of-s3-data"><span class="me-2">Running Spark Job on top of S3 Data</span><a href="#running-spark-job-on-top-of-s3-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>After submitting Spark Job, now it works and queries Data from partitions prefixes S3 Bucket:</p><div class="language-shell highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre>+----------+--------------------+
|customerId|     recommendations|
+----------+--------------------+
|     15992|[<span class="o">{</span>22983, 1.283649...|
|     15237|[<span class="o">{</span>21064, 1.094786...|
|     17668|[<span class="o">{</span>85114, 1.253556...|
+----------+--------------------+

+------+--------------------+
|itemId|     recommendations|
+------+--------------------+
| 21209|[<span class="o">{</span>17119, 1.570859...|
| 22129|[<span class="o">{</span>16402, 0.956514...|
| 22429|[<span class="o">{</span>16781, 1.282029...|
+------+--------------------+
</pre></table></code></div></div><h2 id="acknowledgements"><span class="me-2">Acknowledgements</span><a href="#acknowledgements" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><p>EMR makes it easy to provision resources, scale instances submit and monitor jobs. Regarding storage besides standard <code class="language-plaintext highlighter-rouge">HDFS</code> it provides <code class="language-plaintext highlighter-rouge">EMRFS</code> - a robust implementation of Hadoop Distributed File System (HDFS) used by all Amazon EMR clusters. It empowers clusters to seamlessly read and write regular files from Amazon EMR directly to Amazon S3, offering a blend of convenience and powerful features.</p><h2 id="references-links"><span class="me-2">References (Links)</span><a href="#references-links" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2><ul><li><a href="https://github.com/tsypuk/samples/tree/main/emr">EMR samples with code and DataSet</a><li><a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-master-core-task-nodes.html">EMR node types</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/aws/">aws</a>, <a href="/categories/kinesis/">kinesis</a>, <a href="/categories/s3/">s3</a>, <a href="/categories/firehose/">firehose</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/aws/" class="post-tag no-text-decoration" >aws</a> <a href="/tags/kinesis/" class="post-tag no-text-decoration" >kinesis</a> <a href="/tags/s3/" class="post-tag no-text-decoration" >s3</a> <a href="/tags/firehose/" class="post-tag no-text-decoration" >firehose</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Running%20Recommendation%20Engine%20Spark%20Job%20on%20EMR%20-%20Engineer's%20Notes&url=https%3A%2F%2Ftsypuk.github.io%2Fposts%2F2023%2F10%2F19%2Femr-spark.html" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Running%20Recommendation%20Engine%20Spark%20Job%20on%20EMR%20-%20Engineer's%20Notes&u=https%3A%2F%2Ftsypuk.github.io%2Fposts%2F2023%2F10%2F19%2Femr-spark.html" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Ftsypuk.github.io%2Fposts%2F2023%2F10%2F19%2Femr-spark.html&text=Running%20Recommendation%20Engine%20Spark%20Job%20on%20EMR%20-%20Engineer's%20Notes" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Ftsypuk.github.io%2Fposts%2F2023%2F10%2F19%2Femr-spark.html" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Linkedin" aria-label="Linkedin"> <i class="fa-fw fab fa-linkedin"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/2025/09/26/multiagnet-n8n-bedrock.html">Orchestrating AI multi-agent infrastructure with AWS Bedrock, OpenAI and n8n</a><li class="text-truncate lh-lg"> <a href="/posts/2025/07/20/elastic-cache-vector.html">Amazon ElastiCache Redis as a Vector Embeddings Storage for Semantic Search in AWS Community Blog posts</a><li class="text-truncate lh-lg"> <a href="/posts/2025/09/17/duckdb-s3.html">Running analytics queries from your machine with Zero-BigData stack needed on top of AWS S3(compressed JSON, Parquet, csv) or other DataSources</a><li class="text-truncate lh-lg"> <a href="/posts/2023/10/02/dynamo-design.html">DynamoDB Table Design Principles - NoSQL Modeling</a><li class="text-truncate lh-lg"> <a href="/posts/2023/10/04/dynamo-one-to-many.html">DynamoDB Table Design Principles - One-To-Many Relationships in NoSQL</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/aws/">aws</a> <a class="post-tag btn btn-outline-primary" href="/tags/dynamodb/">dynamodb</a> <a class="post-tag btn btn-outline-primary" href="/tags/git/">git</a> <a class="post-tag btn btn-outline-primary" href="/tags/security/">security</a> <a class="post-tag btn btn-outline-primary" href="/tags/s3/">s3</a> <a class="post-tag btn btn-outline-primary" href="/tags/ecs/">ecs</a> <a class="post-tag btn btn-outline-primary" href="/tags/network/">network</a> <a class="post-tag btn btn-outline-primary" href="/tags/cli/">cli</a> <a class="post-tag btn btn-outline-primary" href="/tags/fargate/">fargate</a> <a class="post-tag btn btn-outline-primary" href="/tags/firehose/">firehose</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/2023/10/18/kineses-firehose.html" class="post-preview card h-100"><div class="card-body"> <time data-ts="1697637600" data-df="ll" > Oct 18, 2023 </time><h4 class="pt-0 my-2">Connecting Kinesis Firehose DataStream with aws-kinesis-agent to ingest Log Data into AWS S3</h4><div class="text-muted"><p>Abstract AWS Kinesis Firehose is a powerful service that enables almost real-time data streaming at scale. It simplifies the process of ingesting, transforming, and loading large volumes of data in...</p></div></div></a></article><article class="col"> <a href="/posts/2023/10/17/kineses-agent.html" class="post-preview card h-100"><div class="card-body"> <time data-ts="1697551200" data-df="ll" > Oct 17, 2023 </time><h4 class="pt-0 my-2">AWS Kinesis Agent configuration and setup for Data Streaming to the Cloud</h4><div class="text-muted"><p>Abstract Amazon Kinesis Agent is a powerful tool that helps you collect, process, and transfer data in real-time to AWS services like Amazon Kinesis Data Streams, Amazon Kinesis Data Firehose, and...</p></div></div></a></article><article class="col"> <a href="/posts/2024/02/03/s3-signed-urls.html" class="post-preview card h-100"><div class="card-body"> <time data-ts="1706968800" data-df="ll" > Feb 3, 2024 </time><h4 class="pt-0 my-2">AWS S3-presigned URLs: Deep Dive and Use Cases of secure file transfers</h4><div class="text-muted"><p>Abstract One of AWS S3 features is very useful, but not so many developers and architects are familiar with it - the capability to generate presigned URLs. In this blog post, we will explore wha...</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/2023/10/18/kineses-firehose.html" class="btn btn-outline-primary" aria-label="Older" ><p>Connecting Kinesis Firehose DataStream with aws-kinesis-agent to ingest Log Data into AWS S3</p></a> <a href="/posts/2023/11/12/comprehend.html" class="btn btn-outline-primary" aria-label="Newer" ><p>Sentimental Analysis of popular movies using Managed AWS ML Comprehend service</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://www.linkedin.com/in/roman-tsypuk">Roman Tsypuk</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span> <span data-bs-toggle="tooltip" data-bs-placement="top" title="2025-09-26 20:11:52 +0300 &#013;be60bb44e6416aa69b8fd68791db025be40c523c">Build version: be60bb4</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.2.4" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/aws/">aws</a> <a class="post-tag btn btn-outline-primary" href="/tags/dynamodb/">dynamodb</a> <a class="post-tag btn btn-outline-primary" href="/tags/git/">git</a> <a class="post-tag btn btn-outline-primary" href="/tags/security/">security</a> <a class="post-tag btn btn-outline-primary" href="/tags/s3/">s3</a> <a class="post-tag btn btn-outline-primary" href="/tags/ecs/">ecs</a> <a class="post-tag btn btn-outline-primary" href="/tags/network/">network</a> <a class="post-tag btn btn-outline-primary" href="/tags/cli/">cli</a> <a class="post-tag btn btn-outline-primary" href="/tags/fargate/">fargate</a> <a class="post-tag btn btn-outline-primary" href="/tags/firehose/">firehose</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> (function () { const themeMapper = Theme.getThemeMapper('light', 'dark_dimmed'); const initTheme = themeMapper[Theme.visualState]; let lang = 'en';if (lang.length > 2 && !lang.startsWith('zh')) { lang = lang.slice(0, 2); } let giscusAttributes = { src: 'https://giscus.app/client.js', 'data-repo': 'tsypuk/tsypuk.github.io', 'data-repo-id': 'R_kgDOIxaFiw', 'data-category': 'General', 'data-category-id': 'DIC_kwDOIxaFi84CUSfn', 'data-mapping': 'og:title', 'data-strict' : '0', 'data-reactions-enabled': '1', 'data-emit-metadata': '0', 'data-theme': initTheme, 'data-input-position': 'top', 'data-lang': lang, 'data-loading': 'lazy', crossorigin: 'anonymous', async: '' }; let giscusNode = document.createElement('script'); Object.entries(giscusAttributes).forEach(([key, value]) => giscusNode.setAttribute(key, value) ); const $footer = document.querySelector('footer'); $footer.insertAdjacentElement("beforebegin", giscusNode); addEventListener('message', (event) => { if (event.source === window && event.data && event.data.id === Theme.ID) { const newTheme = themeMapper[Theme.visualState]; const message = { setConfig: { theme: newTheme } }; const giscus = document.getElementsByClassName('giscus-frame')[0].contentWindow; giscus.postMessage({ giscus: message }, 'https://giscus.app'); } }); })(); </script> <script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{content}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
